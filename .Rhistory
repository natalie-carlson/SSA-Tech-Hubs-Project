fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
# extract logliks from each topic
logLiks_many <- lapply(fitted_many, function(L)  L@logLiks[-c(1:(burnin/keep))])
# compute harmonic means
harmonic_mean <- sapply(logLiks_many, function(h) harmonicMean(h))
# inspect
plot(number_of_topics, harmonic_mean, type = "l")
# compute optimum number of topics
number_of_topics[which.max(harmonic_mean)]
library(topicmodels)
harmonicMean <- function(logLikelihoods, precision=2000L) {
library("Rmpfr")
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
prec = precision) + llMed))))
}
# The log-likelihood values are then determined by first fitting the model using for example
k = 20
burnin = 1000
iter = 1000
keep = 50
text_dfm <- dfm(descriptions$clean_text)
# generate numerous topic models with different numbers of topics
number_of_topics <- seq(2, 50, 1) # in this case a sequence of numbers from 1 to 50, by ones.
set.seed(103)
fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
# extract logliks from each topic
logLiks_many <- lapply(fitted_many, function(L)  L@logLiks[-c(1:(burnin/keep))])
# compute harmonic means
harmonic_mean <- sapply(logLiks_many, function(h) harmonicMean(h))
# inspect
plot(number_of_topics, harmonic_mean, type = "l")
# compute optimum number of topics
number_of_topics[which.max(harmonic_mean)]
library(plyr)
library(dplyr)
library(ggplot2)
library(matrixStats)
library(tm)
library(knitr)
setwd("/Users/nataliecarlson/Desktop/Tech Hubs/SSA Project Data and Analysis")
descriptions <- read.csv("descriptions.csv", header=TRUE, stringsAsFactors=FALSE)
descriptions <- descriptions[,-1]
master <- read.csv("SSA_Startups_4.csv", header=TRUE, stringsAsFactors=FALSE)
master <- master[-1,13:884]
master[master==2] <- 0
#good_data <- filter(master, Q873_1=="" & Q873_2=="")
good_data <- master
good_data <- as.data.frame(sapply(good_data, as.numeric))
good_data <- good_data[,1:870]
num_responses <- colSums(good_data!=0, na.rm=TRUE)
average_scores <- colMeans(good_data, na.rm=TRUE)
standard_devs <- colSds(as.matrix(good_data), na.rm=TRUE)
ggplot() + aes(average_scores) + geom_histogram(binwidth = 0.05) + scale_x_continuous(breaks = scales::pretty_breaks(n = 11), limits = c(-0.05, 1.05))
descriptions$average_score <- average_scores
descriptions$score_sd <- standard_devs
descriptions$num_responses <- num_responses
descriptions$funding_dummy <- ifelse(descriptions$total_funding>0,1,0)
ggplot(descriptions, aes(x=average_scores, fill=factor(funding_dummy))) + geom_histogram(binwidth = 0.05) + scale_x_continuous(breaks = scales::pretty_breaks(n = 11), limits = c(-0.05, 1.05))
ggplot() + aes(average_scores) + geom_histogram(binwidth = 0.1) + scale_x_continuous(breaks = scales::pretty_breaks(n = 11), limits = c(-0.05, 1.05))
ggplot(descriptions, aes(x=average_scores, fill=factor(funding_dummy))) + geom_histogram(binwidth = 0.1) + scale_x_continuous(breaks = scales::pretty_breaks(n = 11), limits = c(-0.05, 1.05))
ggplot(descriptions, aes(x=average_scores, fill=factor(funding_dummy))) + geom_histogram(binwidth = 0.05) + scale_x_continuous(breaks = scales::pretty_breaks(n = 11), limits = c(-0.05, 1.05))
ggplot(descriptions, aes(x=average_scores, y=mean(funding_dummy)) + geom_histogram(binwidth = 0.05) + scale_x_continuous(breaks = scales::pretty_breaks(n = 11), limits = c(-0.05, 1.05))
ggplot(descriptions, aes(x=average_scores, y=mean(funding_dummy))) + geom_histogram(binwidth = 0.05) + scale_x_continuous(breaks = scales::pretty_breaks(n = 11), limits = c(-0.05, 1.05))
ggplot(descriptions, aes(x=average_scores, y=mean(funding_dummy))) + geom_histogram(binwidth = 0.05) + scale_x_continuous(breaks = scales::pretty_breaks(n = 11), limits = c(-0.05, 1.05))
ggplot(descriptions, aes(x=average_scores, y=mean(funding_dummy))) + geom_histogram(binwidth = 0.05, stat="identity") + scale_x_continuous(breaks = scales::pretty_breaks(n = 11), limits = c(-0.05, 1.05))
ggplot(descriptions, aes(x=average_scores, y=mean(funding_dummy))) + geom_bar(binwidth = 0.05, stat="identity") + scale_x_continuous(breaks = scales::pretty_breaks(n = 11), limits = c(-0.05, 1.05))
ggplot(descriptions, aes(x=average_scores)) + geom_histogram(binwidth = 0.05, aes(y=mean(funding_dummy))) + scale_x_continuous(breaks = scales::pretty_breaks(n = 11), limits = c(-0.05, 1.05))
install.packages("gtools")
library(gtools)
descriptions$score_decile <- quantcut(descriptions$average_score, seq(0,1,by=0.1) )
table(descriptions$score_decile)
descriptions$score_decile <- cut(x = descriptions$average_score, breaks = seq(from = 0, to = 1, by = 0.1))
table(descriptions$score_decile)
bin_descriptions <- data.frame(descriptions, bin=cut(descriptions$average_score, c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1), include.lowest=TRUE))
table(bin_descriptions$bin)
bin_descriptions <- data.frame(descriptions, bin=as.numeric(cut(descriptions$average_score, c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1)), include.lowest=TRUE))
table(bin_descriptions$bin)
ggplot(bin_descriptions) + geom_bar(aes(x=bin, y=mean(funding_dummy))) + scale_x_continuous(breaks = scales::pretty_breaks(n = 11))
ggplot(bin_descriptions, aes(x=bin, y=mean(funding_dummy))) + geom_bar() + scale_x_continuous(breaks = scales::pretty_breaks(n = 11))
ggplot(bin_descriptions, aes(x=bin, y=mean(funding_dummy))) + geom_bar(stat="identity") + scale_x_continuous(breaks = scales::pretty_breaks(n = 11))
bin_descriptions <- data.frame(descriptions, bin=cut(descriptions$average_score, c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1), include.lowest=TRUE))
ggplot(bin_descriptions, aes(x=bin, y=mean(funding_dummy))) + geom_bar(stat="identity") + scale_x_continuous(breaks = scales::pretty_breaks(n = 11))
ggplot(bin_descriptions, aes(x=bin, y=mean(funding_dummy))) + geom_bar(stat="identity")
bin_descriptions <- data.frame(descriptions, bin=cut(descriptions$average_score, c(seq(from=0, to=0.1, by=0.05)), include.lowest=TRUE))
ggplot(bin_descriptions, aes(x=bin, y=mean(funding_dummy))) + geom_bar(stat="identity")
table(bin_descriptions$bin)
bin_descriptions <- data.frame(descriptions, bin=cut(descriptions$average_score, c(seq(from=0, to=1, by=0.05)), include.lowest=TRUE))
ggplot(bin_descriptions, aes(x=bin, y=mean(funding_dummy))) + geom_bar(stat="identity")
bin_descriptions <- data.frame(descriptions, bin=cut(descriptions$average_score, c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1), include.lowest=TRUE))
ggplot(bin_descriptions, aes(x=bin, y=mean(funding_dummy))) + geom_bar(stat="identity")
bin_descriptions <- data.frame(descriptions, bin=cut(descriptions$average_score, c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1), include.lowest=TRUE))
ggplot(bin_descriptions, aes(x=bin, y=funding_dummy)) + stat_summary(fun.y="mean", geom="bar")
bin_descriptions <- data.frame(descriptions, bin=cut(descriptions$average_score, c(seq(from=0, to=1, by=0.05)), include.lowest=TRUE))
ggplot(bin_descriptions, aes(x=bin, y=mean(funding_dummy))) + geom_bar(stat="identity")
bin_descriptions <- data.frame(descriptions, bin=cut(descriptions$average_score, c(seq(from=0, to=1, by=0.05)), include.lowest=TRUE))
ggplot(bin_descriptions, aes(x=bin, y=funding_dummy)) + stat_summary(fun.y="mean", geom="bar")
descriptions <- filter(descriptions, num_responses!=0)
bin_descriptions <- data.frame(descriptions, bin=cut(descriptions$average_score, c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1), include.lowest=TRUE))
ggplot(bin_descriptions, aes(x=bin, y=funding_dummy)) + stat_summary(fun.y="mean", geom="bar")
bin_descriptions <- data.frame(descriptions, bin=cut(descriptions$average_score, c(seq(from=0, to=1, by=0.05)), include.lowest=TRUE))
ggplot(bin_descriptions, aes(x=bin, y=funding_dummy)) + stat_summary(fun.y="mean", geom="bar")
descriptions <- filter(descriptions, num_responses!=0)
bin_descriptions <- data.frame(descriptions, bin=cut(descriptions$average_score, c(seq(from=0, to=1, by=0.05)), include.lowest=TRUE))
ggplot(bin_descriptions, aes(x=bin, y=funding_dummy)) + stat_summary(fun.y="mean", geom="bar")
bin_descriptions <- data.frame(descriptions, bin=cut(descriptions$average_score, c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1), include.lowest=TRUE))
ggplot(bin_descriptions, aes(x=bin, y=funding_dummy)) + stat_summary(fun.y="mean", geom="bar")
ggplot(bin_descriptions, aes(x=bin, y=funding_dummy)) + stat_summary(fun.y="mean", geom="bar") + xlab("Less Social <--- Average mTurk Score ---> More Social")
ggplot(bin_descriptions, aes(x=bin, y=funding_dummy)) + stat_summary(fun.y="mean", geom="bar") + xlab("Less Social <--- Average mTurk Score ---> More Social") + ylab("Proportion of Firms Funded")
library(topicmodels)
harmonicMean <- function(logLikelihoods, precision=2000L) {
library("Rmpfr")
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
prec = precision) + llMed))))
}
# The log-likelihood values are then determined by first fitting the model using for example
k = 20
burnin = 1000
iter = 1000
keep = 50
text_dfm <- dfm(descriptions$clean_text)
# generate numerous topic models with different numbers of topics
number_of_topics <- seq(2, 50, 1) # in this case a sequence of numbers from 1 to 50, by ones.
set.seed(104)
fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
library(plyr)
library(dplyr)
library(ggplot2)
library(matrixStats)
library(tm)
library(knitr)
## SET DIRECTORY HERE
setwd("/Users/nataliecarlson/Desktop/Tech Hubs/SSA Project Data and Analysis")
#################################################
# DATA PROCESSING
#################################################
## READ IN MAIN DATA
descriptions <- read.csv("descriptions.csv", header=TRUE, stringsAsFactors=FALSE)
descriptions <- descriptions[,-1]
master <- read.csv("SSA_Startups_4.csv", header=TRUE, stringsAsFactors=FALSE)
master <- master[-1,13:884]
master[master==2] <- 0
#good_data <- filter(master, Q873_1=="" & Q873_2=="")
good_data <- master
good_data <- as.data.frame(sapply(good_data, as.numeric))
good_data <- good_data[,1:870]
num_responses <- colSums(good_data!=0, na.rm=TRUE)
average_scores <- colMeans(good_data, na.rm=TRUE)
standard_devs <- colSds(as.matrix(good_data), na.rm=TRUE)
descriptions$average_score <- average_scores
descriptions$score_sd <- standard_devs
descriptions$num_responses <- num_responses
descriptions$funding_dummy <- ifelse(descriptions$total_funding>0,1,0)
#drop those with no responses
descriptions <- filter(descriptions, num_responses!=0)
#drop outliers
outliers <- quantile(descriptions$total_funding, 0.99)
descriptions <- filter(descriptions, total_funding<outliers)
# CLEAN TEXT FOR TOPIC MODELING
company_details <- descriptions$descriptions
# lowercase
company_details <- tolower(company_details)
company_details <- gsub("[\r\n]", " ", company_details)
# Replace @UserName
company_details <- gsub("@\\w+", " ", company_details)
# Remove punctuation
company_details <- gsub("[[:punct:]]+", " ", company_details)
# Remove digits
company_details <- gsub("[[:digit:]]+", " ", company_details)
# Remove links
company_details <- gsub("http\\w+", " ", company_details)
myStopwords <- c(stopwords(), "e", "s", "m", "d", "t", "africa", "african", "kenya", "kenyan", "nigeria", "nigerian", "uganda", "ugandan", "ghana", "ghanaian", "www", "com", "will", "can", "dazaar", "co", "propeies", "poal", "staups", "enteainment", "â", "pistis", "also", "right")
# Remove Stopwords
company_details <- removeWords(company_details, myStopwords)
# Remove blank spaces at the beginning
company_details <- gsub("^ ", "", company_details)
# Remove blank spaces at the end
company_details <- gsub(" $", "", company_details)
# Remove tabs
company_details <- gsub("[ |\t]{2,}", " ", company_details)
company_details <- gsub("^ *|(?<= ) | *$", "", company_details, perl = TRUE)
descriptions$clean_text <- company_details
## REMOVE DUPLICATES
descriptions$dup1 <- duplicated(descriptions[,1], fromLast = TRUE)
descriptions$dup2 <- duplicated(descriptions[,1], fromLast = FALSE)
#all_duplicates <- filter(descriptions, (dup1==TRUE | dup2==TRUE))
#all_duplicates <- all_duplicates[order(all_duplicates$descriptions),]
duplicates <- filter(descriptions, dup1==TRUE)
descriptions <- filter(descriptions, dup1==FALSE)
descriptions$match <- match(descriptions$descriptions, duplicates$descriptions, nomatch=0)
#average scores for dups
for (i in 1:nrow(descriptions)) {
if (descriptions$dup2[i]==TRUE){
n <- descriptions$match[i]
count <- duplicates$num_responses[n] + descriptions$num_responses[i]
descriptions$average_score[i] <- (duplicates$average_score[n] * (duplicates$num_responses[n]/count)) + (descriptions$average_score[i] * (descriptions$num_responses[i]/count))
descriptions$num_responses[i] <- count
}
}
## CATEGORIES
categories <- read.csv("category_matrix_3.csv", header=TRUE, stringsAsFactors=FALSE)
categories <- categories[,-1]
categories$descriptions <- NULL
descriptions_categories <- merge(descriptions, categories, by.x = c("names"), by.y=c("names"), all.x = TRUE, all.y = FALSE)
descriptions_categories$dup1 <- duplicated(descriptions_categories$descriptions, fromLast = TRUE)
descriptions_categories <- filter(descriptions_categories, dup1==FALSE)
library(topicmodels)
harmonicMean <- function(logLikelihoods, precision=2000L) {
library("Rmpfr")
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
prec = precision) + llMed))))
}
# The log-likelihood values are then determined by first fitting the model using for example
k = 20
burnin = 1000
iter = 1000
keep = 50
text_dfm <- dfm(descriptions$clean_text)
# generate numerous topic models with different numbers of topics
number_of_topics <- seq(2, 50, 1) # in this case a sequence of numbers from 1 to 50, by ones.
set.seed(104)
fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
# extract logliks from each topic
logLiks_many <- lapply(fitted_many, function(L)  L@logLiks[-c(1:(burnin/keep))])
# compute harmonic means
harmonic_mean <- sapply(logLiks_many, function(h) harmonicMean(h))
# inspect
plot(number_of_topics, harmonic_mean, type = "l")
# compute optimum number of topics
number_of_topics[which.max(harmonic_mean)]
library(topicmodels)
harmonicMean <- function(logLikelihoods, precision=2000L) {
library("Rmpfr")
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
prec = precision) + llMed))))
}
# The log-likelihood values are then determined by first fitting the model using for example
k = 20
burnin = 1000
iter = 1000
keep = 50
text_dfm <- dfm(descriptions$clean_text)
# generate numerous topic models with different numbers of topics
number_of_topics <- seq(2, 50, 1) # in this case a sequence of numbers from 1 to 50, by ones.
set.seed(105)
fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
# extract logliks from each topic
logLiks_many <- lapply(fitted_many, function(L)  L@logLiks[-c(1:(burnin/keep))])
# compute harmonic means
harmonic_mean <- sapply(logLiks_many, function(h) harmonicMean(h))
# inspect
plot(number_of_topics, harmonic_mean, type = "l")
# compute optimum number of topics
number_of_topics[which.max(harmonic_mean)]
library(topicmodels)
harmonicMean <- function(logLikelihoods, precision=2000L) {
library("Rmpfr")
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
prec = precision) + llMed))))
}
# The log-likelihood values are then determined by first fitting the model using for example
k = 20
burnin = 1000
iter = 1000
keep = 50
text_dfm <- dfm(descriptions$clean_text)
# generate numerous topic models with different numbers of topics
number_of_topics <- seq(2, 50, 1) # in this case a sequence of numbers from 1 to 50, by ones.
set.seed(106)
fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
# extract logliks from each topic
logLiks_many <- lapply(fitted_many, function(L)  L@logLiks[-c(1:(burnin/keep))])
# compute harmonic means
harmonic_mean <- sapply(logLiks_many, function(h) harmonicMean(h))
# inspect
plot(number_of_topics, harmonic_mean, type = "l")
# compute optimum number of topics
number_of_topics[which.max(harmonic_mean)]
library(topicmodels)
harmonicMean <- function(logLikelihoods, precision=2000L) {
library("Rmpfr")
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
prec = precision) + llMed))))
}
# The log-likelihood values are then determined by first fitting the model using for example
k = 20
burnin = 1000
iter = 1000
keep = 50
text_dfm <- dfm(descriptions$clean_text)
# generate numerous topic models with different numbers of topics
number_of_topics <- seq(2, 50, 1) # in this case a sequence of numbers from 1 to 50, by ones.
set.seed(107)
fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
# extract logliks from each topic
logLiks_many <- lapply(fitted_many, function(L)  L@logLiks[-c(1:(burnin/keep))])
# compute harmonic means
harmonic_mean <- sapply(logLiks_many, function(h) harmonicMean(h))
# inspect
plot(number_of_topics, harmonic_mean, type = "l")
# compute optimum number of topics
number_of_topics[which.max(harmonic_mean)]
library(topicmodels)
harmonicMean <- function(logLikelihoods, precision=2000L) {
library("Rmpfr")
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
prec = precision) + llMed))))
}
# The log-likelihood values are then determined by first fitting the model using for example
k = 20
burnin = 1000
iter = 1000
keep = 50
text_dfm <- dfm(descriptions$clean_text)
# generate numerous topic models with different numbers of topics
number_of_topics <- seq(2, 50, 1) # in this case a sequence of numbers from 1 to 50, by ones.
set.seed(108)
fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
# extract logliks from each topic
logLiks_many <- lapply(fitted_many, function(L)  L@logLiks[-c(1:(burnin/keep))])
# compute harmonic means
harmonic_mean <- sapply(logLiks_many, function(h) harmonicMean(h))
# inspect
plot(number_of_topics, harmonic_mean, type = "l")
# compute optimum number of topics
number_of_topics[which.max(harmonic_mean)]
library(topicmodels)
harmonicMean <- function(logLikelihoods, precision=2000L) {
library("Rmpfr")
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
prec = precision) + llMed))))
}
# The log-likelihood values are then determined by first fitting the model using for example
k = 20
burnin = 1000
iter = 1000
keep = 50
text_dfm <- dfm(descriptions$clean_text)
# generate numerous topic models with different numbers of topics
number_of_topics <- seq(2, 50, 1) # in this case a sequence of numbers from 1 to 50, by ones.
set.seed(109)
fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
# extract logliks from each topic
logLiks_many <- lapply(fitted_many, function(L)  L@logLiks[-c(1:(burnin/keep))])
# compute harmonic means
harmonic_mean <- sapply(logLiks_many, function(h) harmonicMean(h))
# inspect
plot(number_of_topics, harmonic_mean, type = "l")
# compute optimum number of topics
number_of_topics[which.max(harmonic_mean)]
library(topicmodels)
harmonicMean <- function(logLikelihoods, precision=2000L) {
library("Rmpfr")
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
prec = precision) + llMed))))
}
# The log-likelihood values are then determined by first fitting the model using for example
k = 20
burnin = 1000
iter = 1000
keep = 50
text_dfm <- dfm(descriptions$clean_text)
# generate numerous topic models with different numbers of topics
number_of_topics <- seq(2, 50, 1) # in this case a sequence of numbers from 1 to 50, by ones.
set.seed(110)
fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
# extract logliks from each topic
logLiks_many <- lapply(fitted_many, function(L)  L@logLiks[-c(1:(burnin/keep))])
# compute harmonic means
harmonic_mean <- sapply(logLiks_many, function(h) harmonicMean(h))
# inspect
plot(number_of_topics, harmonic_mean, type = "l")
# compute optimum number of topics
number_of_topics[which.max(harmonic_mean)]
library(topicmodels)
harmonicMean <- function(logLikelihoods, precision=2000L) {
library("Rmpfr")
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
prec = precision) + llMed))))
}
# The log-likelihood values are then determined by first fitting the model using for example
k = 20
burnin = 1000
iter = 1000
keep = 50
text_dfm <- dfm(descriptions$clean_text)
# generate numerous topic models with different numbers of topics
number_of_topics <- seq(2, 50, 1) # in this case a sequence of numbers from 1 to 50, by ones.
set.seed(111)
fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
# extract logliks from each topic
logLiks_many <- lapply(fitted_many, function(L)  L@logLiks[-c(1:(burnin/keep))])
# compute harmonic means
harmonic_mean <- sapply(logLiks_many, function(h) harmonicMean(h))
# inspect
plot(number_of_topics, harmonic_mean, type = "l")
# compute optimum number of topics
number_of_topics[which.max(harmonic_mean)]
library(topicmodels)
harmonicMean <- function(logLikelihoods, precision=2000L) {
library("Rmpfr")
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
prec = precision) + llMed))))
}
# The log-likelihood values are then determined by first fitting the model using for example
k = 20
burnin = 1000
iter = 1000
keep = 50
text_dfm <- dfm(descriptions$clean_text)
# generate numerous topic models with different numbers of topics
number_of_topics <- seq(2, 50, 1) # in this case a sequence of numbers from 1 to 50, by ones.
set.seed(112)
fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
# extract logliks from each topic
logLiks_many <- lapply(fitted_many, function(L)  L@logLiks[-c(1:(burnin/keep))])
# compute harmonic means
harmonic_mean <- sapply(logLiks_many, function(h) harmonicMean(h))
# inspect
plot(number_of_topics, harmonic_mean, type = "l")
# compute optimum number of topics
number_of_topics[which.max(harmonic_mean)]
library(topicmodels)
harmonicMean <- function(logLikelihoods, precision=2000L) {
library("Rmpfr")
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
prec = precision) + llMed))))
}
# The log-likelihood values are then determined by first fitting the model using for example
k = 20
burnin = 1000
iter = 1000
keep = 50
text_dfm <- dfm(descriptions$clean_text)
# generate numerous topic models with different numbers of topics
number_of_topics <- seq(2, 50, 1) # in this case a sequence of numbers from 1 to 50, by ones.
set.seed(113)
fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
# extract logliks from each topic
logLiks_many <- lapply(fitted_many, function(L)  L@logLiks[-c(1:(burnin/keep))])
# compute harmonic means
harmonic_mean <- sapply(logLiks_many, function(h) harmonicMean(h))
# inspect
plot(number_of_topics, harmonic_mean, type = "l")
# compute optimum number of topics
number_of_topics[which.max(harmonic_mean)]
library(topicmodels)
harmonicMean <- function(logLikelihoods, precision=2000L) {
library("Rmpfr")
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
prec = precision) + llMed))))
}
# The log-likelihood values are then determined by first fitting the model using for example
k = 20
burnin = 1000
iter = 1000
keep = 50
text_dfm <- dfm(descriptions$clean_text)
# generate numerous topic models with different numbers of topics
number_of_topics <- seq(2, 50, 1) # in this case a sequence of numbers from 1 to 50, by ones.
set.seed(114)
fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
# extract logliks from each topic
logLiks_many <- lapply(fitted_many, function(L)  L@logLiks[-c(1:(burnin/keep))])
# compute harmonic means
harmonic_mean <- sapply(logLiks_many, function(h) harmonicMean(h))
# inspect
plot(number_of_topics, harmonic_mean, type = "l")
# compute optimum number of topics
number_of_topics[which.max(harmonic_mean)]
library(topicmodels)
harmonicMean <- function(logLikelihoods, precision=2000L) {
library("Rmpfr")
llMed <- median(logLikelihoods)
as.double(llMed - log(mean(exp(-mpfr(logLikelihoods,
prec = precision) + llMed))))
}
# The log-likelihood values are then determined by first fitting the model using for example
k = 20
burnin = 1000
iter = 1000
keep = 50
text_dfm <- dfm(descriptions$clean_text)
# generate numerous topic models with different numbers of topics
number_of_topics <- seq(2, 50, 1) # in this case a sequence of numbers from 1 to 50, by ones.
set.seed(115)
fitted_many <- lapply(number_of_topics, function(k) LDA(text_dfm, k = k, method = "Gibbs",control = list(burnin = burnin, iter = iter, keep = keep) ))
# extract logliks from each topic
logLiks_many <- lapply(fitted_many, function(L)  L@logLiks[-c(1:(burnin/keep))])
# compute harmonic means
harmonic_mean <- sapply(logLiks_many, function(h) harmonicMean(h))
# inspect
plot(number_of_topics, harmonic_mean, type = "l")
# compute optimum number of topics
number_of_topics[which.max(harmonic_mean)]
View(descriptions)
mean(descriptions$num_responses)
sd(descriptions$average_score)
mean(descriptions$average_score)
mean(descriptions$funding_dummy)
